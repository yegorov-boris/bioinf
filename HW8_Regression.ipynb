{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия\n",
    "__Суммарное количество баллов: 10__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path=\"./hw9_data/boston.csv\"):\n",
    "    dataframe = np.genfromtxt(path, delimiter=\",\", skip_header=15)\n",
    "    X = dataframe[:, :-1]\n",
    "    y = dataframe[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic(size, dim=6, noise=0.1):\n",
    "    X = np.random.randn(size, dim)\n",
    "    w = np.random.randn(dim + 1)\n",
    "    noise = noise * np.random.randn(size)\n",
    "    y = X.dot(w[1:]) + w[0] + noise\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (1 балл)\n",
    "Для начала нужно понять, какую метрику для ошибки будем использовать. В нашем случае нам подойдет стандартная метрика MSE. Ее и нужно реализовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_predicted):\n",
    "    return np.mean((y_true - y_predicted)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (3 балла)\n",
    "Теперь реализуем линейную регрессию при помощи явного решения задачи минимизации. \n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - решает задачу минимизации $\\arg\\min_{w, b}\\sum ((w\\cdot x + b) - y)^2$. \n",
    "\n",
    "`predict(X)` - строит предсказание `y` для объектов из `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalLR:\n",
    "    def fit(self, X, y):\n",
    "        x = self.extend(X)\n",
    "        xt_x_inv = np.linalg.inv(np.dot(x.T, x))\n",
    "        xt_y = np.dot(x.T, y)\n",
    "        self.w = np.dot(xt_x_inv, xt_y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(self.extend(X), self.w)\n",
    "    \n",
    "    def extend(self, X):\n",
    "        x = np.array(X)\n",
    "        ones = list(map(lambda _: 1, X))\n",
    "        return np.insert(x, 0, ones, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_synthetic(1024)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.11 ms, sys: 1.55 ms, total: 6.66 ms\n",
      "Wall time: 340 ms\n",
      "0.010770445934890096\n"
     ]
    }
   ],
   "source": [
    "regr = NormalLR()\n",
    "%time regr.fit(X_train, y_train)\n",
    "print(mse(y_test, regr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 (2 балла)\n",
    "Теперь реализуем линейную регрессию с использованием градиентного спуска с larning rate `alpha` в течении `iterations` итераций.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - приближает решение задачи минимизации $\\arg\\min_{w, b}\\sum ((w\\cdot x + b) - y)^2$ при помощи градиентного спуска. \n",
    "\n",
    "\n",
    "`predict(X)` - строит предсказание `y` для объектов из `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 (2 балла)\n",
    "Добавьте в метод `fit` регуляризацию Лассо с коэффициентом `l`. Постройте график зависимости ошибки предсказания данных из синтетического набора данных от коэффициента регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientLR:\n",
    "    def __init__(self, alpha, iterations=10000, l=0.):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_plot(X_train, y_train, X_test, y_test):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_synthetic(1024)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = GradientLR(0.1, iterations=10000)\n",
    "regr.fit(X_train, y_train)\n",
    "print(mse(y_test, regr.predict(X_test)))\n",
    "build_plot(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5 (2 балла)\n",
    "Протесируйте оба метода на данных cancer и spam, для градиентного спуска постройте график зависимости ошибки от коэффициента регуляризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = NormalLR()\n",
    "regr.fit(X_train, y_train)\n",
    "print(mse(y_test, regr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = GradientLR(0.1, iterations=10000)\n",
    "regr.fit(X_train, y_train)\n",
    "print(mse(y_test, regr.predict(X_test)))\n",
    "build_plot(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
